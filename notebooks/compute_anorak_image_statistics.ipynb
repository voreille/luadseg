{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ed483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2506a070",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_map = {\n",
    "    0: \"background\",\n",
    "    1: \"cribriform\",               # unclear â€” green is not in the original doc\n",
    "    2: \"micropapillary\",\n",
    "    3: \"solid\",\n",
    "    4: \"papillary\",\n",
    "    5: \"acinar\",\n",
    "    6: \"lepidic\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da330df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_to_class = {\n",
    "    \"background\": 0,\n",
    "    \"cribriform\": 1,\n",
    "    \"micropapillary\": 2,\n",
    "    \"solid\": 3,\n",
    "    \"papillary\": 4,\n",
    "    \"acinar\": 5,\n",
    "    \"lepidic\": 6,\n",
    "}\n",
    "# Actually let them as this, not sure about the true class mapping\n",
    "pattern_to_class = {\n",
    "    \"label0\": 0,\n",
    "    \"label1\": 1,\n",
    "    \"label2\": 2,\n",
    "    \"label3\": 3,\n",
    "    \"label4\": 4,\n",
    "    \"label5\": 5,\n",
    "    \"label6\": 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eefe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_directory = Path(\"/home/valentin/workspaces/luadseg/data/processed/ANORAK_not_resized/image\")\n",
    "masks_directory = Path(\"/home/valentin/workspaces/luadseg/data/processed/ANORAK_not_resized/mask_png\")\n",
    "mask_paths = [\n",
    "    f.resolve() for f in masks_directory.glob(\"*.png\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df = pd.DataFrame(columns=[\"image_id\",\"image_width\", \"image_height\", \"background\", \"lepidic\", \"papillary\", \"acinar\", \"cribriform\", \"micropapillary\", \"solid\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605773cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ratios_list = []\n",
    "for mask_path in tqdm(mask_paths, desc=\"Processing masks\"):\n",
    "    image_id = mask_path.stem\n",
    "    image_path_matches = list(images_directory.glob(f\"{image_id}.*\"))\n",
    "    if not image_path_matches:\n",
    "        print(f\"No image found for {image_id}\")\n",
    "        continue\n",
    "    if len(image_path_matches) > 1:\n",
    "        print(f\"Multiple images found for {image_id}: {image_path_matches}\")\n",
    "        continue\n",
    "    image_path = image_path_matches[0]\n",
    "\n",
    "    image = cv2.imread(\n",
    "        str(image_path),\n",
    "        cv2.IMREAD_UNCHANGED,\n",
    "    )\n",
    "    mask = cv2.imread(\n",
    "        str(mask_path),\n",
    "        cv2.IMREAD_UNCHANGED,\n",
    "    )\n",
    "    h_image, w_image = image.shape[:2]\n",
    "    h_mask, w_mask = mask.shape[:2]\n",
    "\n",
    "    if w_image != w_mask or h_image != h_mask:\n",
    "        print(f\"Image and mask dimensions do not match for {image_id}: \"\n",
    "              f\"image ({w_image}, {h_image}), mask ({w_mask}, {h_mask})\")\n",
    "        continue\n",
    "\n",
    "    if mask is None:\n",
    "        print(f\"Mask not found for {image_id}\")\n",
    "        continue\n",
    "\n",
    "    # Count the number of pixels for each class\n",
    "    pattern_dict = {k: np.sum(mask == v) for k, v in pattern_to_class.items()}\n",
    "\n",
    "    ratios_list.append(\n",
    "        {\n",
    "            \"image_id\": image_id,\n",
    "            \"image_width\": w_image,\n",
    "            \"image_height\": h_image,\n",
    "            **pattern_dict,\n",
    "        }\n",
    "    )\n",
    "\n",
    "ratio_df = pd.DataFrame(ratios_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e87d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df = ratio_df.sort_values(by=\"image_id\").reset_index(drop=True)\n",
    "ratio_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f5b055",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df[\"image_area\"] = ratio_df[\"image_height\"] * ratio_df[\"image_width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d9007",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    ratio_df[f\"label{i}_ratio\"] = ratio_df[f\"label{i}\"] / ratio_df[\"image_area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d10df1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df.to_csv(\"/home/valentin/workspaces/luadseg/data/processed/ANORAK_not_resized/class_ratios.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c1e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [f\"label{i}\" for i in range(7)]\n",
    "\n",
    "# Total pixel count per label\n",
    "total_pixels_per_label = ratio_df[label_cols].sum()\n",
    "\n",
    "# Min and max image width and height\n",
    "min_width = ratio_df[\"image_width\"].min()\n",
    "max_width = ratio_df[\"image_width\"].max()\n",
    "min_height = ratio_df[\"image_height\"].min()\n",
    "max_height = ratio_df[\"image_height\"].max()\n",
    "\n",
    "# Display the results\n",
    "print(\"Total pixels per label:\")\n",
    "print(total_pixels_per_label)\n",
    "\n",
    "print(\"\\nImage width range: \", min_width, \"to\", max_width)\n",
    "print(\"Image height range:\", min_height, \"to\", max_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfa1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_small_image = (ratio_df[\"image_height\"] < 256) | (ratio_df[\"image_width\"] < 256)\n",
    "mask_small_image_count = mask_small_image.sum()\n",
    "print(f\"\\nNumber of images smaller than 256x256: {mask_small_image_count}\")\n",
    "print(f\"with image_ids: {ratio_df[mask_small_image]['image_id'].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb78b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "df = ratio_df.copy()\n",
    "\n",
    "# Identify dominant class by max pixel count among label columns\n",
    "label_cols = [\"label0\", \"label1\", \"label2\", \"label3\", \"label4\", \"label5\", \"label6\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8ca49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dominant_class\"] = df[label_cols].idxmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0469169",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pixels_per_label / total_pixels_per_label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify small images\n",
    "df[\"is_small\"] = (df[\"image_width\"] < 256) | (df[\"image_height\"] < 256)\n",
    "\n",
    "# Separate normal and small images\n",
    "df_normal = df[~df[\"is_small\"]].copy()\n",
    "df_small = df[df[\"is_small\"]].copy()\n",
    "\n",
    "# Set up stratified 5-fold split on normal images\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=137)\n",
    "folds = []\n",
    "\n",
    "image_ids = df_normal[\"image_id\"].values\n",
    "labels = df_normal[\"dominant_class\"].values\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(skf.split(image_ids, labels)):\n",
    "    train_ids = df_normal.iloc[train_idx][\"image_id\"].tolist()\n",
    "    test_ids = df_normal.iloc[test_idx][\"image_id\"].tolist()\n",
    "    \n",
    "    # Add small images to training\n",
    "    train_ids += df_small[\"image_id\"].tolist()\n",
    "    \n",
    "    folds.append({\n",
    "        \"fold\": fold_idx,\n",
    "        \"train\": train_ids,\n",
    "        \"test\": test_ids,\n",
    "    })\n",
    "\n",
    "    print(f\"Fold {fold_idx}: {len(train_ids)} train, {len(test_ids)} test\")\n",
    "    df_test = df[df[\"image_id\"].isin(test_ids)].copy()\n",
    "    total_pixels_per_label = df_test[label_cols].sum()\n",
    "    total_pixels = total_pixels_per_label.sum()\n",
    "    ratio_pixels_per_label = total_pixels_per_label / total_pixels\n",
    "\n",
    "    print(f\"Ratio of pixels per label for fold {fold_idx}:\")\n",
    "    print(ratio_pixels_per_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00851b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ratio_df.copy()\n",
    "\n",
    "\n",
    "# Mark small images\n",
    "df[\"is_small\"] = (df[\"image_width\"] < 256) | (df[\"image_height\"] < 256)\n",
    "\n",
    "df[\"dominant_class\"] = df[label_cols].idxmax(axis=1)\n",
    "# Separate normal and small images\n",
    "df_normal = df[~df[\"is_small\"]].copy()\n",
    "df_small = df[df[\"is_small\"]].copy()\n",
    "\n",
    "# Initialize fold assignments and label pixel counters\n",
    "n_folds = 5\n",
    "fold_pixel_totals = [defaultdict(int) for _ in range(n_folds)]\n",
    "image_assignments = []\n",
    "\n",
    "# Sort images by total number of labeled pixels (descending, for more even balance)\n",
    "df_normal[\"total_pixels\"] = df_normal[label_cols].sum(axis=1)\n",
    "df_normal_sorted = df_normal.sort_values(\"total_pixels\", ascending=False)\n",
    "\n",
    "# Assign each image to the fold that has the least pixels for its dominant class\n",
    "for _, row in df_normal_sorted.iterrows():\n",
    "    dominant_class = row[\"dominant_class\"]\n",
    "    pixel_counts = [fold[dominant_class] for fold in fold_pixel_totals]\n",
    "    target_fold = pixel_counts.index(min(pixel_counts))\n",
    "\n",
    "    # Assign image to this fold\n",
    "    image_assignments.append((row[\"image_id\"], target_fold))\n",
    "\n",
    "    # Update fold pixel totals\n",
    "    for label in label_cols:\n",
    "        fold_pixel_totals[target_fold][label] += row[label]\n",
    "\n",
    "# Format the result into fold splits\n",
    "folds = []\n",
    "for fold_idx in range(n_folds):\n",
    "    test_ids = [img_id for img_id, f in image_assignments if f == fold_idx]\n",
    "    train_ids = [img_id for img_id, f in image_assignments if f != fold_idx]\n",
    "    train_ids += df_small[\"image_id\"].tolist()  # Add small images to every training set\n",
    "\n",
    "    folds.append({\n",
    "        \"fold\": fold_idx,\n",
    "        \"train\": train_ids,\n",
    "        \"test\": test_ids,\n",
    "    })\n",
    "\n",
    "    # Summary printout\n",
    "    print(f\"Fold {fold_idx}: {len(train_ids)} train, {len(test_ids)} test\")\n",
    "\n",
    "    df_test = df[df[\"image_id\"].isin(test_ids)].copy()\n",
    "    total_pixels_per_label = df_test[label_cols].sum()\n",
    "    total_pixels = total_pixels_per_label.sum()\n",
    "    ratio_pixels_per_label = total_pixels_per_label / total_pixels\n",
    "\n",
    "    print(f\"Ratio of pixels per label for fold {fold_idx}:\")\n",
    "\n",
    "    print(ratio_pixels_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4609ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = ratio_df.copy()\n",
    "n_folds = 5\n",
    "label_cols = [f\"label{i}\" for i in range(7)]\n",
    "\n",
    "# Mark small images\n",
    "df[\"is_small\"] = (df[\"image_width\"] < 256) | (df[\"image_height\"] < 256)\n",
    "df[\"dominant_class\"] = df[label_cols].idxmax(axis=1)\n",
    "\n",
    "# Separate normal and small images\n",
    "df_normal = df[~df[\"is_small\"]].copy()\n",
    "df_small = df[df[\"is_small\"]].copy()\n",
    "df_normal[\"total_pixels\"] = df_normal[label_cols].sum(axis=1)\n",
    "\n",
    "# Sort normal images by total pixels\n",
    "df_normal_sorted = df_normal.sort_values(\"total_pixels\", ascending=False)\n",
    "\n",
    "# Assign test folds with pixel-based stratification\n",
    "test_fold_pixel_totals = [defaultdict(int) for _ in range(n_folds)]\n",
    "test_assignments = {}\n",
    "\n",
    "for _, row in df_normal_sorted.iterrows():\n",
    "    dom = row[\"dominant_class\"]\n",
    "    counts = [fold[dom] for fold in test_fold_pixel_totals]\n",
    "    fold_id = counts.index(min(counts))\n",
    "    test_assignments[row[\"image_id\"]] = fold_id\n",
    "    for label in label_cols:\n",
    "        test_fold_pixel_totals[fold_id][label] += row[label]\n",
    "\n",
    "# Now build full split_df\n",
    "records = []\n",
    "\n",
    "for fold_idx in range(n_folds):\n",
    "    test_ids = [img_id for img_id, f in test_assignments.items() if f == fold_idx]\n",
    "    small_ids = df_small[\"image_id\"].tolist()\n",
    "    \n",
    "    # Remaining normal images for training/val\n",
    "    remaining = df_normal[~df_normal[\"image_id\"].isin(test_ids)].copy()\n",
    "    remaining = remaining.sort_values(\"total_pixels\", ascending=False)\n",
    "    \n",
    "    val_fold_pixel_totals = defaultdict(int)\n",
    "    val_ids = []\n",
    "    train_ids = []\n",
    "\n",
    "    for _, row in remaining.iterrows():\n",
    "        dom = row[\"dominant_class\"]\n",
    "        val_count = val_fold_pixel_totals[dom]\n",
    "        total_count = sum(val_fold_pixel_totals.values()) + 1e-6  # avoid div0\n",
    "        dom_ratio = val_count / total_count\n",
    "\n",
    "        # Heuristic: if class ratio is under 20%, accept into val\n",
    "        if dom_ratio < 0.2 and len(val_ids) < 0.15 * len(remaining):\n",
    "            val_ids.append(row[\"image_id\"])\n",
    "            for label in label_cols:\n",
    "                val_fold_pixel_totals[label] += row[label]\n",
    "        else:\n",
    "            train_ids.append(row[\"image_id\"])\n",
    "    \n",
    "    # Add small images to train set only\n",
    "    train_ids += small_ids\n",
    "\n",
    "    # Create full record\n",
    "    for img_id in df[\"image_id\"]:\n",
    "        records.append({\n",
    "            \"image_id\": img_id,\n",
    "            \"fold\": fold_idx,\n",
    "            \"is_train\": img_id in train_ids,\n",
    "            \"is_val\": img_id in val_ids,\n",
    "            \"is_test\": img_id in test_ids,\n",
    "        })\n",
    "\n",
    "# Store in split_df\n",
    "split_df = pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1587a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.to_csv(\"/home/valentin/workspaces/luadseg/data/processed/ANORAK_not_resized/split_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61dbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checking if an image is taken only once in the dataset for the test set\n",
    "split_df.groupby(\"image_id\").agg({\n",
    "    \"is_train\": \"sum\",\n",
    "    \"is_val\": \"sum\",\n",
    "    \"is_test\": \"sum\",\n",
    "    \"fold\": \"first\",\n",
    "}).reset_index()[\"is_test\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ef80aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_idx in range(n_folds):\n",
    "    test_ids = split_df[(split_df[\"fold\"] == fold_idx) & (split_df[\"is_test\"])][\"image_id\"].tolist()\n",
    "    df_test = ratio_df[ratio_df[\"image_id\"].isin(test_ids)].copy()\n",
    "    total_pixels_per_label = df_test[label_cols].sum()\n",
    "    total_pixels = total_pixels_per_label.sum()\n",
    "    ratio_pixels_per_label = total_pixels_per_label / total_pixels\n",
    "\n",
    "    print(f\"Ratio of pixels per label for fold {fold_idx}:\")\n",
    "\n",
    "    print(ratio_pixels_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40fc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_idx in range(n_folds):\n",
    "    val_ids = split_df[(split_df[\"fold\"] == fold_idx) & (split_df[\"is_val\"])][\"image_id\"].tolist()\n",
    "    df_val = ratio_df[ratio_df[\"image_id\"].isin(val_ids)].copy()\n",
    "    total_pixels_per_label = df_val[label_cols].sum()\n",
    "    total_pixels = total_pixels_per_label.sum()\n",
    "    ratio_pixels_per_label = total_pixels_per_label / total_pixels\n",
    "\n",
    "    print(f\"Ratio of pixels per label for fold {fold_idx}:\")\n",
    "\n",
    "    print(ratio_pixels_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f481d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_idx in range(n_folds):\n",
    "    train_ids = split_df[(split_df[\"fold\"] == fold_idx) & (split_df[\"is_train\"])][\"image_id\"].tolist()\n",
    "    df_train = ratio_df[ratio_df[\"image_id\"].isin(train_ids)].copy()\n",
    "    total_pixels_per_label = df_train[label_cols].sum()\n",
    "    total_pixels = total_pixels_per_label.sum()\n",
    "    ratio_pixels_per_label = total_pixels_per_label / total_pixels\n",
    "\n",
    "    print(f\"Ratio of pixels per label for fold {fold_idx}:\")\n",
    "\n",
    "    print(ratio_pixels_per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2030a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
